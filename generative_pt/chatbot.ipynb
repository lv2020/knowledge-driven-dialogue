{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuJHdCVc3F9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8562e01e-4a7e-43cd-a43c-024f9725ac7c"
      },
      "source": [
        "!pip install torch\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.2.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY6k2Pc24suV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d898a53a-341b-4902-ada0-19f6b7757483"
      },
      "source": [
        "import os\n",
        "os.chdir('/root')\n",
        "!git clone https://github.com/lv2020/knowledge-driven-dialogue.git\n",
        "os.chdir('/root/knowledge-driven-dialogue/generative_pt')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'knowledge-driven-dialogue'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/79)\u001b[K\rremote: Counting objects:   2% (2/79)\u001b[K\rremote: Counting objects:   3% (3/79)\u001b[K\rremote: Counting objects:   5% (4/79)\u001b[K\rremote: Counting objects:   6% (5/79)\u001b[K\rremote: Counting objects:   7% (6/79)\u001b[K\rremote: Counting objects:   8% (7/79)\u001b[K\rremote: Counting objects:  10% (8/79)\u001b[K\rremote: Counting objects:  11% (9/79)\u001b[K\rremote: Counting objects:  12% (10/79)\u001b[K\rremote: Counting objects:  13% (11/79)\u001b[K\rremote: Counting objects:  15% (12/79)\u001b[K\rremote: Counting objects:  16% (13/79)\u001b[K\rremote: Counting objects:  17% (14/79)\u001b[K\rremote: Counting objects:  18% (15/79)\u001b[K\rremote: Counting objects:  20% (16/79)\u001b[K\rremote: Counting objects:  21% (17/79)\u001b[K\rremote: Counting objects:  22% (18/79)\u001b[K\rremote: Counting objects:  24% (19/79)\u001b[K\rremote: Counting objects:  25% (20/79)\u001b[K\rremote: Counting objects:  26% (21/79)\u001b[K\rremote: Counting objects:  27% (22/79)\u001b[K\rremote: Counting objects:  29% (23/79)\u001b[K\rremote: Counting objects:  30% (24/79)\u001b[K\rremote: Counting objects:  31% (25/79)\u001b[K\rremote: Counting objects:  32% (26/79)\u001b[K\rremote: Counting objects:  34% (27/79)\u001b[K\rremote: Counting objects:  35% (28/79)\u001b[K\rremote: Counting objects:  36% (29/79)\u001b[K\rremote: Counting objects:  37% (30/79)\u001b[K\rremote: Counting objects:  39% (31/79)\u001b[K\rremote: Counting objects:  40% (32/79)\u001b[K\rremote: Counting objects:  41% (33/79)\u001b[K\rremote: Counting objects:  43% (34/79)\u001b[K\rremote: Counting objects:  44% (35/79)\u001b[K\rremote: Counting objects:  45% (36/79)\u001b[K\rremote: Counting objects:  46% (37/79)\u001b[K\rremote: Counting objects:  48% (38/79)\u001b[K\rremote: Counting objects:  49% (39/79)\u001b[K\rremote: Counting objects:  50% (40/79)\u001b[K\rremote: Counting objects:  51% (41/79)\u001b[K\rremote: Counting objects:  53% (42/79)\u001b[K\rremote: Counting objects:  54% (43/79)\u001b[K\rremote: Counting objects:  55% (44/79)\u001b[K\rremote: Counting objects:  56% (45/79)\u001b[K\rremote: Counting objects:  58% (46/79)\u001b[K\rremote: Counting objects:  59% (47/79)\u001b[K\rremote: Counting objects:  60% (48/79)\u001b[K\rremote: Counting objects:  62% (49/79)\u001b[K\rremote: Counting objects:  63% (50/79)\u001b[K\rremote: Counting objects:  64% (51/79)\u001b[K\rremote: Counting objects:  65% (52/79)\u001b[K\rremote: Counting objects:  67% (53/79)\u001b[K\rremote: Counting objects:  68% (54/79)\u001b[K\rremote: Counting objects:  69% (55/79)\u001b[K\rremote: Counting objects:  70% (56/79)\u001b[K\rremote: Counting objects:  72% (57/79)\u001b[K\rremote: Counting objects:  73% (58/79)\u001b[K\rremote: Counting objects:  74% (59/79)\u001b[K\rremote: Counting objects:  75% (60/79)\u001b[K\rremote: Counting objects:  77% (61/79)\u001b[K\rremote: Counting objects:  78% (62/79)\u001b[K\rremote: Counting objects:  79% (63/79)\u001b[K\rremote: Counting objects:  81% (64/79)\u001b[K\rremote: Counting objects:  82% (65/79)\u001b[K\rremote: Counting objects:  83% (66/79)\u001b[K\rremote: Counting objects:  84% (67/79)\u001b[K\rremote: Counting objects:  86% (68/79)\u001b[K\rremote: Counting objects:  87% (69/79)\u001b[K\rremote: Counting objects:  88% (70/79)\u001b[K\rremote: Counting objects:  89% (71/79)\u001b[K\rremote: Counting objects:  91% (72/79)\u001b[K\rremote: Counting objects:  92% (73/79)\u001b[K\rremote: Counting objects:  93% (74/79)\u001b[K\rremote: Counting objects:  94% (75/79)\u001b[K\rremote: Counting objects:  96% (76/79)\u001b[K\rremote: Counting objects:  97% (77/79)\u001b[K\rremote: Counting objects:  98% (78/79)\u001b[K\rremote: Counting objects: 100% (79/79)\u001b[K\rremote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 352 (delta 20), reused 47 (delta 6), pack-reused 273\u001b[K\n",
            "Receiving objects: 100% (352/352), 115.58 MiB | 28.53 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n",
            "Checking out files: 100% (189/189), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI_pqfuM9F7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "515d47a2-cbd2-418e-993c-00d3a61c9101"
      },
      "source": [
        "import os\n",
        "list_file = os.listdir(os.getcwd())\n",
        "print(list_file)\n",
        "!ls -l /bin/sh\n",
        "!echo no | sudo dpkg-reconfigure dash\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sample.train.txt', 'output', 'run_test.sh', 'sample.text.txt', 'source', 'sample.test.txt', 'log.txt', 'tools', 'models', 'README.md', 'data', 'run_train.sh', 'sample.dev.txt', 'network.py']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlDcsFS--teK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6e09fa7-7f98-4d78-be15-fde3339a9141"
      },
      "source": [
        "\n",
        "!sh run_train.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "KnowledgeSeq2Seq(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embedder): Embedder(2132, 300, padding_idx=0)\n",
            "    (rnn): GRU(300, 400, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (bridge): Sequential(\n",
            "    (0): Linear(in_features=800, out_features=800, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (knowledge_encoder): RNNEncoder(\n",
            "    (embedder): Embedder(2132, 300, padding_idx=0)\n",
            "    (rnn): GRU(300, 400, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (prior_attention): Attention(800, 800, mode='dot')\n",
            "  (posterior_attention): Attention(800, 800, mode='dot')\n",
            "  (decoder): RNNDecoder(\n",
            "    (embedder): Embedder(2132, 300, padding_idx=0)\n",
            "    (attention): Attention(800, 800, mode='dot')\n",
            "    (rnn): GRU(1100, 800, batch_first=True)\n",
            "    (cue_rnn): GRU(1600, 800, batch_first=True)\n",
            "    (fc1): Linear(in_features=800, out_features=800, bias=True)\n",
            "    (fc2): Linear(in_features=800, out_features=800, bias=True)\n",
            "    (fc3): Linear(in_features=1600, out_features=1, bias=True)\n",
            "    (tanh): Tanh()\n",
            "    (sigmoid): Sigmoid()\n",
            "    (output_layer): Sequential(\n",
            "      (0): Dropout(p=0.3)\n",
            "      (1): Linear(in_features=1600, out_features=800, bias=True)\n",
            "      (2): Linear(in_features=800, out_features=2132, bias=True)\n",
            "      (3): LogSoftmax()\n",
            "    )\n",
            "  )\n",
            "  (log_softmax): LogSoftmax()\n",
            "  (softmax): Softmax()\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softplus): Softplus(beta=1, threshold=20)\n",
            "  (bow_output_layer): Sequential(\n",
            "    (0): Linear(in_features=800, out_features=800, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=800, out_features=2132, bias=True)\n",
            "    (3): LogSoftmax()\n",
            "  )\n",
            "  (nll_loss): NLLLoss()\n",
            "  (kl_loss): KLDivLoss()\n",
            ")\n",
            "Number of parameters: 21599865\n",
            "\n",
            "Training starts ...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1992: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "NLL-103.658   NLL_PPL-2136.448   ACC-0.000   KL-0.139   BOW-103.770   LOSS-207.567\n",
            "\n",
            "=====================================================================================\n",
            "================================== Model Training ===================================\n",
            "=====================================================================================\n",
            "\n",
            "Generation starts ...\n",
            "Avg_Len-30.000   Bleu-0.0028/0.0025   Inter_Dist-0.0011/0.0110\n",
            "Target:   AVG_LEN-12.520   Inter_Dist-0.0118/0.1496\n",
            "Saved model state to './models/state_epoch_1.model'\n",
            "Saved train state to './models/state_epoch_1.train'\n",
            "\n",
            "\n",
            "=====================================================================================\n",
            "================================== Model Training ===================================\n",
            "=====================================================================================\n",
            "\n",
            "Generation starts ...\n",
            "Avg_Len-30.000   Bleu-0.0027/0.0024   Inter_Dist-0.0011/0.0108\n",
            "Target:   AVG_LEN-12.520   Inter_Dist-0.0118/0.1496\n",
            "Saved model state to './models/state_epoch_2.model'\n",
            "Saved train state to './models/state_epoch_2.train'\n",
            "\n",
            "\n",
            "=====================================================================================\n",
            "================================== Model Training ===================================\n",
            "=====================================================================================\n",
            "\n",
            "Generation starts ...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}